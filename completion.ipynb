{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\summarizerP39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\user\\anaconda3\\envs\\summarizerP39\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (None)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the unmasker, most of the bert family work.\n",
    "# (if you are changing the unmasker, also change the mask token to the one yours uses)\n",
    "unmasker = pipeline('fill-mask', model='xlm-roberta-large', device=0)\n",
    "mask_token = \"<mask>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to generate a random sequence of words\n",
    "# seed length refers to the amount of words to be generated\n",
    "# this function is used when generating the un-completed text for the model for the first time\n",
    "def random_seed(seed_length):\n",
    "    # generate a random sequence of numbers from 0 to 2999 (because there are 3000 words in the text file)\n",
    "    seed = np.random.randint(0, 2999, seed_length)\n",
    "    # we will be adding the words to this variable\n",
    "    sequence = \"\"\n",
    "    \n",
    "    # change the filepath to wherever your text file is located\n",
    "    # text file should be formatted like so:\n",
    "    #     word 1\n",
    "    #     word 2\n",
    "    #     ...\n",
    "    #     word 2999\n",
    "    #     word 3000\n",
    "    \n",
    "    with open(r\"C:\\Users\\user\\Desktop\\text nn\\words.txt\") as file:\n",
    "        # replace the file to be the words in it, in a list\n",
    "        # [word 1, word 2, ... word 2999, word 3000]\n",
    "        file = file.read().split(\"\\n\")\n",
    "        \n",
    "        # loop over the random sequence generated earlier\n",
    "        for x in seed:\n",
    "            # and add the word correspondint to the current number to the sequence\n",
    "            sequence += f\"{file[int(x)]} \"\n",
    "\n",
    "    # reuturn the sequence accept the last character since its a space\n",
    "    # the space is added to seperate the words at the ned of each word, so there is a space after the last word\n",
    "    return sequence[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to go over the text with a mask once\n",
    "# text is reffering to the text we are trying to modify\n",
    "# topic is referring to what we are trying to complete the text to\n",
    "def run_mask(text, topic):\n",
    "    # split the text into individual words\n",
    "    split_text = text.split()\n",
    "    \n",
    "    # loop over each word\n",
    "    for x in range(len(split_text)):\n",
    "        # change the current word we are looping on to the mask token\n",
    "        split_text[x] = mask_token\n",
    "        # combine the topic with the whole text (now with the mask token on one of the words)\n",
    "        # example:\n",
    "        #            topic                    masked text\n",
    "        #  ____________|___________    ____________|___________\n",
    "        # |                       |   |                       |\n",
    "        # apples are green because    they have <mask> in them.\n",
    "        masked = f\"\"\"{topic} {\" \".join(split_text)}.\"\"\"\n",
    "        # change the masked word to whatever the model predicted\n",
    "        split_text[x] = unmasker(masked)[0][\"token_str\"]\n",
    "    \n",
    "    # return the text, this time we turn the list back into a sentence\n",
    "    return \" \".join(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an all in one function to completly modify the trext towards the topic\n",
    "# text is reffering to the text we are trying to modify\n",
    "# topic is referring to what we are trying to complete the text to\n",
    "def run_text(text, topic):\n",
    "    # this counts the number of edurations we have done over the text\n",
    "    # its not required, its only used in tthe print command\n",
    "    edurations = 0\n",
    "    \n",
    "    # loop until the text stops being changed by the model\n",
    "    # this means its done tuning it\n",
    "    while True:\n",
    "        # add an eduration\n",
    "        edurations += 1\n",
    "        \n",
    "        # set the previous text as a variable\n",
    "        # this is used to check if the model stopped changing the sentence\n",
    "        ptext = text\n",
    "        \n",
    "        # run the mask over the current text\n",
    "        text = run_mask(text, topic)\n",
    "        \n",
    "        # this is just used to monitor the models progress\n",
    "        print(f\"{edurations}: {topic}   --->   {text}\")\n",
    "        \n",
    "        # check if the new sentence is equal to the previous sentence,\n",
    "        # if it is, then we can stop the loop.\n",
    "        if text == ptext:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: lemons are   --->   the best not the best to make a new , you are a bit old\n",
      "2: lemons are   --->   the best and the way to start something new when you get a little tired\n",
      "3: lemons are   --->   the best and easy way to try something new when you are a little older\n",
      "4: lemons are   --->   the quick and easy way to try something new when you get a little tired\n",
      "5: lemons are   --->   a quick and easy way to try something new when you are a little tired\n",
      "6: lemons are   --->   a quick and easy way to try something new when you are a little tired\n"
     ]
    }
   ],
   "source": [
    "run_text(random_seed(15), \"lemons are\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summarizerP39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
